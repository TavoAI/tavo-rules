version: '1.0'
id: tavoai-mit-risk-R001
name: 'MIT AI Risk: AI systems that create unfair discrimination'
category: ethics
subcategory: discrimination
severity: high
rule_type: hybrid
standards:
  mit_ai_risk:
  - discrimination-and-toxicity
  iso_42001:
  - 6.2.2
  - 7.7.1
  nist_ai_rmf:
  - MEASURE-2.2
  - VALIDATE-2.3
  cwe:
  - CWE-710
  - CWE-20
  capec:
  - CAPEC-183
  - CAPEC-165
compatible_models:
- openai/gpt-4
- anthropic/claude-3-opus
tags: &id001
- mit-ai-risk
- discrimination
- ai-risk-repository
heuristics:
- type: semgrep
  languages:
  - python
  pattern: model\.fit\(.*\).*gender|race|age
  message: Potential discriminatory model training
  severity: high
- type: semgrep
  languages:
  - python
  - javascript
  - typescript
  pattern: .*systems.*
  message: Potential systems risk detected
  severity: low
- type: semgrep
  languages:
  - python
  - javascript
  - typescript
  pattern: .*that.*
  message: Potential that risk detected
  severity: low
ai_analysis:
  trigger:
  - always
  high_risk_patterns:
  - '*/discrimination/*'
  - '*/ai/*'
  - '*/model/*'
  prompt_template: "Analyze this AI system for the following MIT AI Risk Repository\
    \ risk:\n\n        Risk: AI systems that create unfair discrimination\n      \
    \  Domain: Discrimination & Toxicity\n        Entity: AI\n        Intent: Unintentional\n\
    \        Timing: Post-deployment\n\n        Code to analyze:\n        {{code_snippet}}\n\
    \n        File: {{file_path}}\n        Context: {{heuristic_findings}}\n\n   \
    \     Evaluate whether this code exhibits the risk described above. Consider:\n\
    \        1. Does the code enable or contribute to this specific risk?\n      \
    \  2. Are there mitigating factors present?\n        3. What is the severity and\
    \ likelihood of this risk occurring?\n        4. What remediation steps would\
    \ address this risk?\n\n        Focus on the specific characteristics of this\
    \ risk from the MIT AI Risk Repository."
  expected_response_schema:
    type: object
    required:
    - severity
    - vulnerable_lines
    - description
    - remediation
    - standards_mapping
    - confidence
    properties:
      severity:
        enum:
        - low
        - medium
        - high
        - critical
      vulnerable_lines:
        type: array
        items:
          type: number
      description:
        type: string
        minLength: 100
      remediation:
        type: string
        minLength: 100
      standards_mapping:
        type: object
      confidence:
        type: number
        minimum: 0
        maximum: 1
execution:
  max_tokens: 2000
  temperature: 0.1
sarif_output:
  rule_id: tavoai-mit-risk-R001
  rule_name: 'MIT AI Risk: AI systems that create unfair discrimination'
  short_description: AI systems that create unfair discrimination
  full_description: 'AI systems that create unfair discrimination


    Source: AI Risk Repository Test

    Authors: MIT Team

    Year: 2024'
  help_uri: https://airisk.mit.edu/risk/R001
  tags: *id001
