rules:
  - id: llm06-sensitive-info-disclosure
    message: "Sensitive information disclosure: Potential leakage of secrets or PII in prompts"
    languages: [python, javascript, typescript]
    pattern: |
      $LLM.chat.completions.create(
        ...,
        messages=[
          ...,
          {
            "role": "user",
            "content": "...password..." + $SECRET + "..."
          },
          ...
        ],
        ...
      )
    severity: CRITICAL
    metadata:
      cwe: "CWE-200"
      owasp-llm: "LLM06"
      category: "sensitive-information-disclosure"
      description: "Detects potential disclosure of sensitive information in LLM prompts"

  - id: llm06-debug-info-leakage
    message: "Debug information leakage: Internal system details exposed in LLM interactions"
    languages: [python, javascript, typescript]
    pattern: |
      $LLM.chat.completions.create(
        ...,
        messages=[
          ...,
          {
            "role": "system",
            "content": "...debug=true..."
          },
          ...
        ],
        ...
      )
    severity: HIGH
    metadata:
      cwe: "CWE-200"
      owasp-llm: "LLM06"
      category: "sensitive-information-disclosure"
      description: "Detects exposure of debug information or internal system details"

  - id: llm06-training-data-leakage
    message: "Training data leakage: Proprietary training data potentially exposed"
    languages: [python, javascript, typescript]
    pattern: |
      print($TRAINING_DATA)
    severity: HIGH
    metadata:
      cwe: "CWE-200"
      owasp-llm: "LLM06"
      category: "sensitive-information-disclosure"
      description: "Detects potential leakage of proprietary training data through LLM outputs"
